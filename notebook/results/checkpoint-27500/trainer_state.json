{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.942120466459827,
  "eval_steps": 500,
  "global_step": 27500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05349309939017867,
      "grad_norm": 0.6157875061035156,
      "learning_rate": 1.9646945544024823e-05,
      "loss": 0.235,
      "step": 500
    },
    {
      "epoch": 0.10698619878035734,
      "grad_norm": 0.5674015879631042,
      "learning_rate": 1.9290324881423633e-05,
      "loss": 0.1378,
      "step": 1000
    },
    {
      "epoch": 0.160479298170536,
      "grad_norm": 0.35841381549835205,
      "learning_rate": 1.893370421882244e-05,
      "loss": 0.1373,
      "step": 1500
    },
    {
      "epoch": 0.21397239756071468,
      "grad_norm": 0.36481973528862,
      "learning_rate": 1.857708355622125e-05,
      "loss": 0.1343,
      "step": 2000
    },
    {
      "epoch": 0.26746549695089333,
      "grad_norm": 0.3853970766067505,
      "learning_rate": 1.822046289362006e-05,
      "loss": 0.1309,
      "step": 2500
    },
    {
      "epoch": 0.320958596341072,
      "grad_norm": 0.6465558409690857,
      "learning_rate": 1.7863842231018866e-05,
      "loss": 0.1305,
      "step": 3000
    },
    {
      "epoch": 0.37445169573125064,
      "grad_norm": 0.2857813537120819,
      "learning_rate": 1.7507221568417676e-05,
      "loss": 0.1308,
      "step": 3500
    },
    {
      "epoch": 0.42794479512142936,
      "grad_norm": 0.41148141026496887,
      "learning_rate": 1.7150600905816483e-05,
      "loss": 0.1295,
      "step": 4000
    },
    {
      "epoch": 0.481437894511608,
      "grad_norm": 0.4222314655780792,
      "learning_rate": 1.6793980243215293e-05,
      "loss": 0.1288,
      "step": 4500
    },
    {
      "epoch": 0.5349309939017867,
      "grad_norm": 0.32494494318962097,
      "learning_rate": 1.6437359580614103e-05,
      "loss": 0.1299,
      "step": 5000
    },
    {
      "epoch": 0.5884240932919653,
      "grad_norm": 0.6993133425712585,
      "learning_rate": 1.608073891801291e-05,
      "loss": 0.1309,
      "step": 5500
    },
    {
      "epoch": 0.641917192682144,
      "grad_norm": 0.5496408343315125,
      "learning_rate": 1.572411825541172e-05,
      "loss": 0.127,
      "step": 6000
    },
    {
      "epoch": 0.6954102920723226,
      "grad_norm": 0.43100443482398987,
      "learning_rate": 1.536749759281053e-05,
      "loss": 0.1256,
      "step": 6500
    },
    {
      "epoch": 0.7489033914625013,
      "grad_norm": 0.49240586161613464,
      "learning_rate": 1.5010876930209338e-05,
      "loss": 0.1228,
      "step": 7000
    },
    {
      "epoch": 0.80239649085268,
      "grad_norm": 0.37928810715675354,
      "learning_rate": 1.4654256267608146e-05,
      "loss": 0.1257,
      "step": 7500
    },
    {
      "epoch": 0.8558895902428587,
      "grad_norm": 0.4654674828052521,
      "learning_rate": 1.4298348846332158e-05,
      "loss": 0.1276,
      "step": 8000
    },
    {
      "epoch": 0.9093826896330374,
      "grad_norm": 0.3538779616355896,
      "learning_rate": 1.3941728183730968e-05,
      "loss": 0.1243,
      "step": 8500
    },
    {
      "epoch": 0.962875789023216,
      "grad_norm": 0.28583911061286926,
      "learning_rate": 1.3585107521129774e-05,
      "loss": 0.1312,
      "step": 9000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.11859449744224548,
      "eval_runtime": 461.8561,
      "eval_samples_per_second": 40.476,
      "eval_steps_per_second": 10.12,
      "step": 9347
    },
    {
      "epoch": 1.0163688884133946,
      "grad_norm": 0.41127169132232666,
      "learning_rate": 1.3228486858528584e-05,
      "loss": 0.1242,
      "step": 9500
    },
    {
      "epoch": 1.0698619878035733,
      "grad_norm": 0.3797702193260193,
      "learning_rate": 1.2871866195927394e-05,
      "loss": 0.1157,
      "step": 10000
    },
    {
      "epoch": 1.123355087193752,
      "grad_norm": 0.6227406859397888,
      "learning_rate": 1.25152455333262e-05,
      "loss": 0.1169,
      "step": 10500
    },
    {
      "epoch": 1.1768481865839306,
      "grad_norm": 0.3207803964614868,
      "learning_rate": 1.215862487072501e-05,
      "loss": 0.1186,
      "step": 11000
    },
    {
      "epoch": 1.2303412859741094,
      "grad_norm": 0.4625977873802185,
      "learning_rate": 1.180200420812382e-05,
      "loss": 0.1124,
      "step": 11500
    },
    {
      "epoch": 1.283834385364288,
      "grad_norm": 0.3407890200614929,
      "learning_rate": 1.1445383545522627e-05,
      "loss": 0.1176,
      "step": 12000
    },
    {
      "epoch": 1.3373274847544667,
      "grad_norm": 0.42639070749282837,
      "learning_rate": 1.1088762882921437e-05,
      "loss": 0.1174,
      "step": 12500
    },
    {
      "epoch": 1.3908205841446453,
      "grad_norm": 0.41901472210884094,
      "learning_rate": 1.0732142220320246e-05,
      "loss": 0.1141,
      "step": 13000
    },
    {
      "epoch": 1.444313683534824,
      "grad_norm": 0.3751932680606842,
      "learning_rate": 1.0375521557719054e-05,
      "loss": 0.1173,
      "step": 13500
    },
    {
      "epoch": 1.4978067829250028,
      "grad_norm": 0.35162806510925293,
      "learning_rate": 1.0018900895117864e-05,
      "loss": 0.1128,
      "step": 14000
    },
    {
      "epoch": 1.5512998823151813,
      "grad_norm": 0.35078394412994385,
      "learning_rate": 9.663706715167077e-06,
      "loss": 0.1149,
      "step": 14500
    },
    {
      "epoch": 1.6047929817053599,
      "grad_norm": 0.4595462381839752,
      "learning_rate": 9.307086052565887e-06,
      "loss": 0.1169,
      "step": 15000
    },
    {
      "epoch": 1.6582860810955387,
      "grad_norm": 0.410284161567688,
      "learning_rate": 8.950465389964695e-06,
      "loss": 0.1113,
      "step": 15500
    },
    {
      "epoch": 1.7117791804857174,
      "grad_norm": 0.25328677892684937,
      "learning_rate": 8.593844727363503e-06,
      "loss": 0.1149,
      "step": 16000
    },
    {
      "epoch": 1.765272279875896,
      "grad_norm": 0.2815222144126892,
      "learning_rate": 8.237224064762313e-06,
      "loss": 0.1165,
      "step": 16500
    },
    {
      "epoch": 1.8187653792660745,
      "grad_norm": 0.5153366923332214,
      "learning_rate": 7.880603402161122e-06,
      "loss": 0.1151,
      "step": 17000
    },
    {
      "epoch": 1.8722584786562533,
      "grad_norm": 0.360563725233078,
      "learning_rate": 7.523982739559931e-06,
      "loss": 0.113,
      "step": 17500
    },
    {
      "epoch": 1.925751578046432,
      "grad_norm": 0.2890985608100891,
      "learning_rate": 7.167362076958739e-06,
      "loss": 0.1129,
      "step": 18000
    },
    {
      "epoch": 1.9792446774366108,
      "grad_norm": 0.40455180406570435,
      "learning_rate": 6.810741414357549e-06,
      "loss": 0.1135,
      "step": 18500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.11587274819612503,
      "eval_runtime": 463.0873,
      "eval_samples_per_second": 40.368,
      "eval_steps_per_second": 10.093,
      "step": 18694
    },
    {
      "epoch": 2.032737776826789,
      "grad_norm": 0.3112124502658844,
      "learning_rate": 6.454120751756357e-06,
      "loss": 0.1137,
      "step": 19000
    },
    {
      "epoch": 2.086230876216968,
      "grad_norm": 0.3559054434299469,
      "learning_rate": 6.097500089155166e-06,
      "loss": 0.1096,
      "step": 19500
    },
    {
      "epoch": 2.1397239756071467,
      "grad_norm": 0.4402216076850891,
      "learning_rate": 5.740879426553975e-06,
      "loss": 0.1116,
      "step": 20000
    },
    {
      "epoch": 2.1932170749973254,
      "grad_norm": 0.5238280892372131,
      "learning_rate": 5.384258763952784e-06,
      "loss": 0.1096,
      "step": 20500
    },
    {
      "epoch": 2.246710174387504,
      "grad_norm": 0.3320372402667999,
      "learning_rate": 5.027638101351593e-06,
      "loss": 0.1096,
      "step": 21000
    },
    {
      "epoch": 2.3002032737776825,
      "grad_norm": 0.3235066831111908,
      "learning_rate": 4.6710174387504015e-06,
      "loss": 0.1085,
      "step": 21500
    },
    {
      "epoch": 2.3536963731678613,
      "grad_norm": 0.41274240612983704,
      "learning_rate": 4.314396776149211e-06,
      "loss": 0.1071,
      "step": 22000
    },
    {
      "epoch": 2.40718947255804,
      "grad_norm": 0.3276349604129791,
      "learning_rate": 3.957776113548019e-06,
      "loss": 0.1064,
      "step": 22500
    },
    {
      "epoch": 2.460682571948219,
      "grad_norm": 0.2843802571296692,
      "learning_rate": 3.601155450946828e-06,
      "loss": 0.1098,
      "step": 23000
    },
    {
      "epoch": 2.514175671338397,
      "grad_norm": 0.5549394488334656,
      "learning_rate": 3.244534788345637e-06,
      "loss": 0.1078,
      "step": 23500
    },
    {
      "epoch": 2.567668770728576,
      "grad_norm": 0.297656387090683,
      "learning_rate": 2.887914125744446e-06,
      "loss": 0.11,
      "step": 24000
    },
    {
      "epoch": 2.6211618701187547,
      "grad_norm": 0.353456050157547,
      "learning_rate": 2.5312934631432544e-06,
      "loss": 0.1101,
      "step": 24500
    },
    {
      "epoch": 2.6746549695089334,
      "grad_norm": 0.42576009035110474,
      "learning_rate": 2.1746728005420635e-06,
      "loss": 0.1074,
      "step": 25000
    },
    {
      "epoch": 2.728148068899112,
      "grad_norm": 0.3594461679458618,
      "learning_rate": 1.8180521379408725e-06,
      "loss": 0.1073,
      "step": 25500
    },
    {
      "epoch": 2.7816411682892905,
      "grad_norm": 0.47031840682029724,
      "learning_rate": 1.4614314753396814e-06,
      "loss": 0.1051,
      "step": 26000
    },
    {
      "epoch": 2.8351342676794693,
      "grad_norm": 0.34311962127685547,
      "learning_rate": 1.1048108127384902e-06,
      "loss": 0.1058,
      "step": 26500
    },
    {
      "epoch": 2.888627367069648,
      "grad_norm": 0.4031136631965637,
      "learning_rate": 7.48190150137299e-07,
      "loss": 0.1076,
      "step": 27000
    },
    {
      "epoch": 2.942120466459827,
      "grad_norm": 0.3567255437374115,
      "learning_rate": 3.9156948753610785e-07,
      "loss": 0.1076,
      "step": 27500
    }
  ],
  "logging_steps": 500,
  "max_steps": 28041,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.983056113664e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
